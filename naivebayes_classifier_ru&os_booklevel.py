# -*- coding: utf-8 -*-
"""NaiveBayes_Classifier_RU&OS_Booklevel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SytVXsT-qXB4QZ90vjPFfdNci_zcikYs
"""

import pandas as pd
import pandas  as pd 
import matplotlib.pyplot as plt 
import numpy as np 
from sklearn.linear_model import LogisticRegression 
from sklearn.preprocessing import StandardScaler 
from sklearn.metrics import confusion_matrix, classification_report 
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
import seaborn as sns
from sklearn.preprocessing import StandardScaler,MinMaxScaler
import imblearn
from imblearn.over_sampling import SMOTE , RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler

dataframe = pd.read_csv(r'/content/Export_Jun-21-2020_1356.csv')
indexNames = dataframe[dataframe['genre'] == 'Unlabelled'].index
dataframe.drop(indexNames , inplace=True)
dataframe = dataframe.drop(['book_name', 'author_name','book_id'], axis = 1)

col_list = dataframe.columns.to_list() 
print(col_list)

def scaledown(columnlist):
  for i in columnlist:
    if str(i) == 'genre' or str(i) == 'Positive_Sentiment' or str(i) == 'Neutral_Sentiment' or str(i) == 'Negative_Sentiment'  or  str(i) == 'book_id' or i == 'TTR':
      pass
    else:
      dataframe[str(i)] = MinMaxScaler().fit_transform(np.array(dataframe[str(i)]).reshape(-1, 1))
scaledown(col_list)

data_split_label = pd.DataFrame([])
data_split = pd.DataFrame([])
#data.drop(dataframe[dataframe['genre'] == 'Allegories'].index, inplace = True)
data_split_label = dataframe['genre']
data_split = dataframe.drop(['genre'], axis = 1) 
print(data_split_label.shape)
print(data_split.shape)

Train_data, Validation_data, Train_label, Validation_label = train_test_split(data_split, data_split_label, train_size = 0.8,random_state = 42)

"""**UnderSampling**"""

sampling_strategy = {'Literary':440}
ros = RandomUnderSampler(random_state=42,sampling_strategy=sampling_strategy)
Underfit_Feature,Underfit_Labels = ros.fit_sample(Train_data, Train_label)

col_list.pop(0)
Underfit_Features = pd.DataFrame(data= Underfit_Feature, columns= col_list)
Underfit_Features.loc[:,'genre'] = pd.Series(Underfit_Labels, index=Underfit_Features.index)
print(Underfit_Features.genre.value_counts())

"""**OverSampling**"""
Final_Labels = pd.DataFrame([])
Underfit_Features .drop(Underfit_Features [Underfit_Features ['genre'] == 'Allegories'].index, inplace = True)
x = Underfit_Features['genre']
Underfit_Features = Underfit_Features.drop(['genre'],axis = 1)
Final_Labels['genre'] = x

Final_Labels.genre.value_counts()

sampling_strategy_smote ={'Christmas Stories':7 ,'Humorous and Wit and Satire':7,'Ghost and Horror':8,'Love and Romance':20,'Western Stories':20,'Sea and Adventure':36,'Detective and Mystery':117}
Smoteobj = SMOTE(k_neighbors=1,sampling_strategy=sampling_strategy_smote)
X_train_res, y_train_res = Smoteobj.fit_sample(Underfit_Features, Final_Labels)

from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(X_train_res, y_train_res)

pred = model.predict(Validation_data)

from sklearn import metrics
score = metrics.accuracy_score(Validation_label, pred)
score1 = metrics.classification_report(Validation_label, pred )
print(score1)
print("accuracy:   %0.5f" % score)